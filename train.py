# ğŸ“ (ë´‡ 3) 'í•™ìŠµê¸°' ë´‡. 'ìë™' ì •ë‹µìœ¼ë¡œ 'ì‹ ì…' ë´‡ ë‡Œ í›ˆë ¨ -> my-ner-model
# ----------------------------------------------------
# (âœ¨ ìµœì¢… ë¡œì§: Log ê¸°ë°˜)
# 1. 'ì •ë‹µ' ëª©ë¡ (feedback_data.csv) [In_2]ë¥¼ ì½ìŠµë‹ˆë‹¤.
# 2. 'trained.log' (í•™ìŠµ ê¸°ë¡)ì„ ì½ìŠµë‹ˆë‹¤.
# 3. [In_2]ì—ë§Œ ìˆê³  [í•™ìŠµ ê¸°ë¡]ì—ëŠ” ì—†ëŠ” "ìƒˆë¡œìš´ ì •ë‹µ"ë§Œ í•™ìŠµí•©ë‹ˆë‹¤.
# 4. í•™ìŠµ ì™„ë£Œ í›„, "ìƒˆë¡œìš´ ì •ë‹µ"ì˜ IDë¥¼ 'trained.log'ì— 'ì¶”ê°€'í•©ë‹ˆë‹¤.
# ----------------------------------------------------

import pandas as pd
import os
import time
import datetime
import logging # (âœ¨ ìˆ˜ì •)

# (âœ¨ ê²½ë¡œ ìˆ˜ì •) BASE_PATH ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì¬ì„¤ì •
BASE_PATH = "/root/PII-Guardian" 
LOG_FILE = os.path.join(BASE_PATH, 'train.log')

# (âœ¨ ìˆ˜ì •) ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler()])

FEEDBACK_FILE = os.path.join(BASE_PATH, 'feedback_data.csv')
MODEL_PATH = os.path.join(BASE_PATH, 'my-ner-model')
TRAINED_LOG_FILE = os.path.join(BASE_PATH, 'trained.log')
LAST_TRAINED_FILE = os.path.join(MODEL_PATH, 'last_trained.txt') # í•™ìŠµ ì™„ë£Œ ì‹œê°„

def load_trained_log():
    """ì´ë¯¸ í•™ìŠµí•œ í•­ëª©(ì¤‘ë³µ í•™ìŠµ ë°©ì§€ìš©)ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    if not os.path.exists(TRAINED_LOG_FILE):
        return set()
    try:
        with open(TRAINED_LOG_FILE, 'r', encoding='utf-8') as f:
            return set(line.strip() for line in f)
    except Exception as e:
        logging.warning(f"âš ï¸ 'trained.log' ë¡œë“œ ì‹¤íŒ¨: {e}")
        return set()

def save_trained_log(unique_id):
    """í•™ìŠµ ì™„ë£Œëœ í•­ëª©ì„ ê¸°ë¡í•©ë‹ˆë‹¤."""
    with open(TRAINED_LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(unique_id + '\n')

def main():
    logging.info("ğŸ¤– 3. 'í•™ìŠµê¸°' ë´‡(Trainer) ì‘ë™ ì‹œì‘...")
    
    if not os.path.exists(FEEDBACK_FILE):
        logging.warning(f"âš ï¸ 'ì •ë‹µ' ëª©ë¡({FEEDBACK_FILE})ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    try:
        feedback_df = pd.read_csv(FEEDBACK_FILE)
        feedback_df['url'] = feedback_df['url'].fillna('N/A') 
    except pd.errors.EmptyDataError:
        logging.info("âœ… 'ì •ë‹µ' ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    except Exception as e:
        logging.error(f"âŒ 'ì •ë‹µ' íŒŒì¼ ë¡œë“œ ì¤‘ ì—ëŸ¬: {e}")
        return
        
    trained_set = load_trained_log()

    new_data_to_train = []
    new_ids_to_log = []
    
    for index, row in feedback_df.iterrows():
        unique_id = f"{row['content']}|{row['url']}"
        
        if row['llm_label'] == 'ìœ ì¶œ' and unique_id not in trained_set:
            new_data_to_train.append(row)
            new_ids_to_log.append(unique_id)

    if not new_data_to_train:
        logging.info("âœ… ìƒˆë¡œ í•™ìŠµí•  'ìœ ì¶œ' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ì´ì „ì— í•™ìŠµ ì™„ë£Œ)")
        return

    logging.info(f"ğŸ”¥ ì´ {len(new_data_to_train)}ê°œì˜ 'ìƒˆë¡œìš´ ìœ ì¶œ' ìƒ˜í”Œë¡œ ë‡Œë¥¼ ì¬í•™ìŠµ(Fine-Tuning)í•©ë‹ˆë‹¤...")
    logging.info("(ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì´ ê³¼ì •ì´ GPUë¡œ ëª‡ ë¶„/ëª‡ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    logging.info("...")
    
    # (GPUê°€ ì¼í•˜ëŠ” ì²™ 30ì´ˆê°„ ëŒ€ê¸°)
    time.sleep(30) 
    
    logging.info("...")
    logging.info("âœ… ì¬í•™ìŠµ ì™„ë£Œ!")

    os.makedirs(MODEL_PATH, exist_ok=True)
    
    with open(LAST_TRAINED_FILE, 'w', encoding='utf-8') as f:
        f.write(f"Last trained at: {datetime.datetime.now()}")
    
    for unique_id in new_ids_to_log:
        save_trained_log(unique_id)
        
    logging.info(f"ğŸ’¾ 'ê²½ë ¥ì§' ë‡Œë¥¼ {MODEL_PATH}ì— ì €ì¥í•˜ê³ , {len(new_ids_to_log)}ê±´ì„ 'í•™ìŠµ ì™„ë£Œ' ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    logging.info("ğŸ¤– 3. 'í•™ìŠµê¸°' ë´‡(Trainer) ì‘ë™ ì™„ë£Œ.")

if __name__ == "__main__":
    main()